{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sent_bert_emb_viz_util import load_data, encode_data_tuple, get_model_from_encoding_output, test_model_from_encoding_output\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "from step4_further_results_from_annotations import get_and_display_results,rule_based_model_ensemble\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input the encoding output_tuple\n",
    "# # output the trained model\n",
    "# # test_size portion \\in (0,1) default as 0.1, not outputting validation results if test_size as 0.\n",
    "# # balanced sampling default as False\n",
    "# # regularisation penalty C default as 1\n",
    "# def get_model_from_encoding_output(output_tuple, num_of_training_samples, test_size=0.1, balanced_sampling=False, C=1):\n",
    "#     if len(output_tuple) == 2:\n",
    "#         X, y = output_tuple\n",
    "#         list_ind_empty_cw, list_ind_wrong_find_mt = [], []\n",
    "#     else:\n",
    "#         X, y, list_ind_empty_cw, list_ind_wrong_find_mt = output_tuple\n",
    "#     # X, y = load_data('mention_disamb_data_features_NCBI_BERT_pubmed_mimic_uncased_L-12_H-768_A-12_sample_89902.pik')\n",
    "#     #print('number of entries with issues: %s+%s' % str(len(list_ind_empty_cw)), str(len(list_ind_wrong_find_mt)))\n",
    "#     #print(list_ind_wrong_find_mt)\n",
    "#     # if not masked_training:\n",
    "#         # #remove the list of index there were eliminated during the wrong_find_mention_token process\n",
    "#         # list_ind_wrong_find_mt = [26964,41622,51767,65705,67399,85607,87693]\n",
    "#         # y = np.array([ele for ind, ele in enumerate(y.tolist()) if ind not in list_ind_wrong_find_mt])\n",
    "    \n",
    "#     print('encoding done')\n",
    "#     #print(y.shape, type(y), len(y.tolist()))\n",
    "#     print('X,y:', X.shape, type(X), y.shape, type(y))\n",
    "#     unique, counts = np.unique(y, return_counts=True)\n",
    "#     #print(unique, counts)\n",
    "#     print('whole data pos:', counts[1], 'neg:', counts[0])\n",
    "\n",
    "#     #data standardisation\n",
    "#     #X = preprocessing.scale(X)\n",
    "\n",
    "#     #data split\n",
    "#     if test_size != 0:\n",
    "#         X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=1234)\n",
    "#     else:\n",
    "#         # if test size not as 0, then do not do data split\n",
    "#         X_train, y_train = X, y\n",
    "        \n",
    "#     training_data_len = X_train.shape[0]\n",
    "#     print(training_data_len)\n",
    "    \n",
    "#     if not balanced_sampling:\n",
    "#         #adjust the number of training samples by the error samples\n",
    "#         #this ensure the different training settings will use the exact same set of training data (while adjusted numbers may be slightly different)\n",
    "#         num_of_training_samples_adjusted = num_of_training_samples\n",
    "#         for ind in list_ind_empty_cw + list_ind_wrong_find_mt:\n",
    "#             if ind < num_of_training_samples:\n",
    "#                 num_of_training_samples_adjusted = num_of_training_samples_adjusted - 1            \n",
    "#         #try only a random sample of the whole training data: the first num_of_training_samples (adjusted by the error samples), X_train is the randomly shuffled data.\n",
    "#         X_train = X_train[:num_of_training_samples_adjusted,:]\n",
    "#         y_train = y_train[:num_of_training_samples_adjusted]\n",
    "#         print(X_train.shape, type(X_train), type(y_train))\n",
    "#     else:\n",
    "#         #sample a label-balanced set from X_train and Y_train\n",
    "#         #and the number of the whole set is equal to num_of_training_samples\n",
    "#         num_tr_samples_per_label = round(num_of_training_samples/2)\n",
    "#         #print(type(num_tr_samples_per_label), num_tr_samples_per_label)\n",
    "#         data_ind_neg = np.where(y_train == 0)[0]\n",
    "#         data_ind_pos = np.where(y_train == 1)[0]\n",
    "#         data_ind_balanced_sample = np.sort(np.concatenate([data_ind_pos[:num_tr_samples_per_label], data_ind_neg[:num_tr_samples_per_label]]))\n",
    "#         X_train = X_train[data_ind_balanced_sample]\n",
    "#         y_train = y_train[data_ind_balanced_sample]\n",
    "#         print(X_train.shape, type(X_train), type(y_train))\n",
    "    \n",
    "#     _, counts = np.unique(y_train, return_counts=True)\n",
    "#     print('training data pos:', counts[1], 'neg:', counts[0])\n",
    "    \n",
    "#     #train\n",
    "#     #clf = SVC(kernel=\"linear\", C=0.025)\n",
    "#     clf = LogisticRegression(C=C, penalty='l2') #solver='liblinear' #max_iter=500\n",
    "#     #clf = LinearRegression()\n",
    "#     #clf = MLPClassifier(hidden_layer_sizes=10)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     #get training results\n",
    "#     y_pred_train = clf.predict(X_train)\n",
    "#     print('training precision:', precision_score(y_pred_train, y_train), 'recall:', recall_score(y_pred_train, y_train), 'F1:', f1_score(y_pred_train, y_train))\n",
    "\n",
    "#     if test_size != 0:\n",
    "#         #get validation results\n",
    "#         y_pred = clf.predict(X_valid)\n",
    "#         print(y_pred, type(y_pred))\n",
    "#         #y_pred = y_pred.round() # for linear regression\n",
    "#         #print(y_pred, y_valid)\n",
    "#         print('validation precision:', precision_score(y_pred, y_valid), 'recall:', recall_score(y_pred, y_valid), 'F1:', f1_score(y_pred, y_valid))\n",
    "    \n",
    "#     return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_model_from_encoding_output(output_tuple_test, num_of_testing_samples, clf):    \n",
    "#     if len(output_tuple_test) == 2:\n",
    "#         X_test, y_test = output_tuple_test\n",
    "#         list_ind_empty_cw_test, list_ind_wrong_find_mt_test = [], []\n",
    "#     else:\n",
    "#         # it also outputs the problematic data entry indexes. we will use these when we fill the results into the spreadsheet.\n",
    "#         X_test, y_test, list_ind_empty_cw_test, list_ind_wrong_find_mt_test = output_tuple_test          \n",
    "#     print('list_ind_empty_cw_test:', list_ind_empty_cw_test)\n",
    "#     print('list_ind_wrong_find_mt_test:', list_ind_wrong_find_mt_test)\n",
    "    \n",
    "#     list_ind_err_test = list_ind_empty_cw_test + list_ind_wrong_find_mt_test\n",
    "#     list_ind_err_test.sort() # sort the index list from low to high\n",
    "#     #adjust the number of testing samples by the error samples\n",
    "#     num_of_testing_samples_adjusted = num_of_testing_samples\n",
    "#     for ind in list_ind_empty_cw_test + list_ind_wrong_find_mt_test:\n",
    "#         if ind < num_of_testing_samples:\n",
    "#             num_of_testing_samples_adjusted = num_of_testing_samples_adjusted - 1\n",
    "            \n",
    "#     print('num_of_whole_testing_data:', len(y_test))\n",
    "#     # to note: there might be unlabelled data in y_test, otherwise 0 or 1.\n",
    "#     # get the labelled part in y_test\n",
    "#     y_test_labelled = [y_test[ind] for ind, y_test_ele in enumerate(y_test) if (y_test_ele == 0 or y_test_ele == 1) and ind<num_of_testing_samples_adjusted]\n",
    "#     print('num_of_actual_testing_data:',len(y_test_labelled))\n",
    "    \n",
    "#     # check the filtered out testing samples\n",
    "#     for ind, y_test_ele in enumerate(y_test):\n",
    "#         if not ((y_test_ele == 0 or y_test_ele == 1)) and ind<num_of_testing_samples_adjusted:\n",
    "#             print('not labelled test sample:',ind,y_test_ele)\n",
    "#             #list_ind_err_test.append(ind) - this is not the original ind, to fix later\n",
    "#     #data standardisation\n",
    "#     #X_test = preprocessing.scale(X_test)\n",
    "\n",
    "#     y_pred_test = clf.predict(X_test)\n",
    "#     #y_pred_test = y_pred_test.round() # for linear regression\n",
    "    \n",
    "#     #print('model results all %s:' % str(len(y_test_labelled)))\n",
    "#     y_pred_test_labelled = [y_pred_test[ind] for ind, y_test_ele in enumerate(y_test) if  (y_test_ele == 0 or y_test_ele == 1) and ind<num_of_testing_samples_adjusted]\n",
    "        \n",
    "#     return y_test_labelled, y_pred_test_labelled, list_ind_err_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_data = True\n",
    "calculate_baseline_results = False\n",
    "test_with_non_rule_annotated_only = False\n",
    "#num_of_testing_items = 50 # this applies only when test_with_non_annotated_only is False\n",
    "\n",
    "masked_training = False\n",
    "use_doc_struc = True\n",
    "\n",
    "rule_based_ensembling = True\n",
    "data_ensembling = False\n",
    "mj_rate = 0.15 #1.0\n",
    "num_sample = 100 #len(data_list_tuples) #500 #len(data_list_tuples) #1000 for quick checking of the program\n",
    "\n",
    "# data selection approaches: random sampling, balanced random sampling, and diverse sampling\n",
    "num_of_training_samples_non_masked = 9000 # much more than the whole data, i.e. using the whole data # 9000\n",
    "num_of_training_samples_masked = 500 # much more than the whole data, i.e. using the whole data # 500\n",
    "balanced_random_sampling=False\n",
    "diverse_sampling=False\n",
    "\n",
    "num_of_data_per_mention=25\n",
    "masking_rate = 1 #0.15 # to implement\n",
    "window_size = 5\n",
    "C = 1 # l2 regularisation parameter\n",
    "\n",
    "num_of_testing_samples = 400\n",
    "\n",
    "#model_path='bert-models\\\\pubmedBERT_tf_model\\\\'; model_name = 'pubmedBERT'\n",
    "#model_path='bert-models\\\\NCBI_BERT_pubmed_mimic_uncased_L-12_H-768_A-12\\\\'; model_name = 'blueBERTnorm'\n",
    "#model_path='bert-models\\\\NCBI_BERT_pubmed_mimic_uncased_L-24_H-1024_A-16\\\\'; model_name = 'blueBERTlarge'\n",
    "\n",
    "marking_str_tr = 'training'\n",
    "\n",
    "#marking_str_te = 'testing_200'    \n",
    "#marking_str_te = 'testing_non_rule_anno'\n",
    "marking_str_te = 'testing_1073'\n",
    "\n",
    "# if masked_training:\n",
    "#     masking_str = '_[MASK]' if masking_rate == 1 else '_[MASK]%s' % str(masking_rate)\n",
    "# else:\n",
    "#     masking_str = ''\n",
    "        \n",
    "trained_models_name = 'model_%s_ws%s%s%s%s.pik' % (model_name, str(window_size), '_ds' if use_doc_struc else '', '_divs%s' % str(num_of_data_per_mention) if diverse_sampling else '','_nm%sm%s' % (str(num_of_training_samples_non_masked),str(num_of_training_samples_masked)))\n",
    "#print(trained_models_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. load data, encoding, and train model \n",
    "#load data\n",
    "data_list_tuples = load_data('mention_disamb_data.pik')\n",
    "random.Random(1234).shuffle(data_list_tuples) #randomly shuffle the list with a random seed        \n",
    "#data_list_tuples = data_list_tuples[0:num_sample] # set a small sample for quick testing\n",
    "print(len(data_list_tuples))\n",
    "\n",
    "print('start encoding')\n",
    "\n",
    "#encoding\n",
    "output_tuple_masked = encode_data_tuple(data_list_tuples, masking=True, with_doc_struc=False, model_path=model_path, marking_str=marking_str_tr, window_size=window_size, masking_rate=masking_rate, diverse_sampling=diverse_sampling, num_of_data_per_mention=num_of_data_per_mention)\n",
    "output_tuple_non_masked_ds = encode_data_tuple(data_list_tuples, masking=False, with_doc_struc=True, model_path=model_path, marking_str=marking_str_tr, window_size=window_size, masking_rate=masking_rate, diverse_sampling=diverse_sampling, num_of_data_per_mention=num_of_data_per_mention)\n",
    "\n",
    "#training\n",
    "clf_model_masked = get_model_from_encoding_output(output_tuple_masked,num_of_training_samples_masked,balanced_sampling=balanced_random_sampling)\n",
    "clf_model_non_masked_ds = get_model_from_encoding_output(output_tuple_non_masked_ds,num_of_training_samples_non_masked,balanced_sampling=balanced_random_sampling)\n",
    "\n",
    "#export models\n",
    "with open(trained_models_name, 'ab') as data_f:\n",
    "    pickle.dump((clf_model_non_masked_ds,clf_model_masked), data_f)\n",
    "    print('\\n' + trained_models_name, 'saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. load testing data and predict results: \n",
    "#load data from .xlsx and save the results to a specific column\n",
    "# get a list of data tuples from an annotated .xlsx file\n",
    "# data format: a 6-element tuple of section_text, document_structure_name, mention_name, UMLS_code, UMLS_desc, label (True or False)\n",
    "df = pd.read_excel('for validation - SemEHR ori.xlsx')\n",
    "# change nan values into empty strings in the two rule-based label columns\n",
    "df[['neg label: only when both rule 0','pos label: both rules applied']] = df[['neg label: only when both rule 0','pos label: both rules applied']].fillna('') \n",
    "# if the data is not labelled, i.e. nan, label it as -1 (not positive or negative)\n",
    "df[['manual label from Hang']] = df[['manual label from Hang']].fillna(-1) \n",
    "\n",
    "data_list_tuples = []\n",
    "for i, row in df.iterrows():\n",
    "    if test_with_non_rule_annotated_only: # only test with those not annotated by rules\n",
    "        #print(row['neg label: only when both rule 0'], type(row['neg label: only when both rule 0']))\n",
    "        if row['neg label: only when both rule 0'] != '' or row['pos label: both rules applied'] != '':\n",
    "            continue\n",
    "    doc_struc = row['document structure']\n",
    "    text = row['Text']\n",
    "    mention = row['mention']\n",
    "    UMLS_code = row['UMLS with desc'].split()[0]\n",
    "    UMLS_desc = ' '.join(row['UMLS with desc'].split()[1:])\n",
    "    #label = row['manual label from Hang']\n",
    "    label = row['gold text-to-UMLS label']\n",
    "    label = 0 if label == -1 else label # assume that the inapplicable (-1) entries are all False.\n",
    "    #print(label)\n",
    "    data_tuple = (text,doc_struc,mention,UMLS_code,UMLS_desc,label)\n",
    "    #if i<2:\n",
    "    #    print(data_tuple)\n",
    "    data_list_tuples.append(data_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get testing data rep and predict with the model\n",
    "# encoding\n",
    "output_tuple_test_masked = encode_data_tuple(data_list_tuples, masking=True, with_doc_struc=False, model_path=model_path, marking_str=marking_str_te, window_size=window_size, masking_rate=masking_rate)\n",
    "output_tuple_test_non_masked_ds = encode_data_tuple(data_list_tuples, masking=False, with_doc_struc=True, model_path=model_path, marking_str=marking_str_te, window_size=window_size, masking_rate=masking_rate)\n",
    "\n",
    "# prediction\n",
    "print('single model results')\n",
    "print('masked training:')\n",
    "y_test_labelled_masked, y_pred_test_labelled_masked,_ = test_model_from_encoding_output(output_tuple_test_masked, num_of_testing_samples, clf_model_masked)\n",
    "get_and_display_results(y_test_labelled_masked, y_pred_test_labelled_masked)\n",
    "\n",
    "print('non-masked training with ds:')\n",
    "y_test_labelled_non_masked_ds, y_pred_test_labelled_non_masked_ds,list_of_err_samples_non_masked = test_model_from_encoding_output(output_tuple_test_non_masked_ds, num_of_testing_samples, clf_model_non_masked_ds)\n",
    "get_and_display_results(y_test_labelled_non_masked_ds, y_pred_test_labelled_non_masked_ds)\n",
    "#also returned the list of erroneous samples using the non-masked encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule-based ensembling\n",
    "y_pred_ment_len = df[['rule (mention length >3)']].to_numpy()\n",
    "y_pred_prevalence = df[['rule (prevalance th <= 0.005)']].to_numpy()\n",
    "\n",
    "y_pred_ment_len_labelled = np.array([y_pred_ment_len[ind] for ind in range(len(y_pred_ment_len)) if ind<num_of_testing_samples and ind not in list_of_err_samples_non_masked])\n",
    "print('y_pred_ment_len_labelled:',len(y_pred_ment_len_labelled))\n",
    "# here we ignored the possibility that if some testing data not labelled to 0 or 1.\n",
    "\n",
    "y_pred_prevalence_labelled = np.array([y_pred_prevalence[ind] for ind in range(len(y_pred_prevalence)) if ind<num_of_testing_samples and ind not in list_of_err_samples_non_masked])\n",
    "print('y_pred_prevalence_labelled:',len(y_pred_prevalence_labelled))\n",
    "\n",
    "print('rule-based model ensemble best scenario results:')\n",
    "# #y_pred_test_m_labelled_ensemb = np.logical_or(y_pred_test_m_labelled,y_pred_test_m_ds_large_labelled).astype(int)\n",
    "y_pred_rule_based_model_ensemble = rule_based_model_ensemble(y_pred_ment_len_labelled, y_pred_prevalence_labelled, y_pred_test_labelled_non_masked_ds, y_pred_test_labelled_masked)\n",
    "get_and_display_results(y_test_labelled_non_masked_ds, y_pred_rule_based_model_ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
